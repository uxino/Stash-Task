{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbf14e2-5630-4dc0-8720-fb7018338f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/museker/Library/Python/3.9/lib/python/site-packages (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/museker/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/museker/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/museker/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/museker/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/museker/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23613309-ef99-48d1-84ef-d6497ff88d50",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae12ecd-6e3e-46df-b16d-4b09f7e30d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/museker/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "overflow encountered in multiply",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/museker/Desktop/task.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/museker/Desktop/task.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m\"\u001b[39;49m\u001b[39mhf://datasets/JonathanSum/github-issues/datasets-issues-with-comments.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m, lines\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/json/_json.py:815\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/json/_json.py:1023\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         data \u001b[39m=\u001b[39m ensure_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[1;32m   1022\u001b[0m         data_lines \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1023\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_combine_lines(data_lines))\n\u001b[1;32m   1024\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/json/_json.py:1051\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1049\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1051\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[1;32m   1053\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1054\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/json/_json.py:1193\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_axes:\n\u001b[1;32m   1192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_axes()\n\u001b[0;32m-> 1193\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_convert_types()\n\u001b[1;32m   1194\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/json/_json.py:1467\u001b[0m, in \u001b[0;36mFrameParser._try_convert_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1465\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dates:\n\u001b[0;32m-> 1467\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_convert_dates()\n\u001b[1;32m   1469\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_converter(\n\u001b[1;32m   1470\u001b[0m     \u001b[39mlambda\u001b[39;00m col, c: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_convert_data(col, c, convert_dates\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1471\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/json/_json.py:1505\u001b[0m, in \u001b[0;36mFrameParser._try_convert_dates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1502\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1505\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_converter(\u001b[39mlambda\u001b[39;49;00m col, c: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_convert_to_date(c), filt\u001b[39m=\u001b[39;49mis_ok)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/json/_json.py:1451\u001b[0m, in \u001b[0;36mFrameParser._process_converter\u001b[0;34m(self, f, filt)\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[39mfor\u001b[39;00m i, (col, c) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(obj\u001b[39m.\u001b[39mitems()):\n\u001b[1;32m   1450\u001b[0m     \u001b[39mif\u001b[39;00m filt(col):\n\u001b[0;32m-> 1451\u001b[0m         new_data, result \u001b[39m=\u001b[39m f(col, c)\n\u001b[1;32m   1452\u001b[0m         \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m   1453\u001b[0m             c \u001b[39m=\u001b[39m new_data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/json/_json.py:1505\u001b[0m, in \u001b[0;36mFrameParser._try_convert_dates.<locals>.<lambda>\u001b[0;34m(col, c)\u001b[0m\n\u001b[1;32m   1502\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1505\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_converter(\u001b[39mlambda\u001b[39;00m col, c: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_convert_to_date(c), filt\u001b[39m=\u001b[39mis_ok)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/json/_json.py:1360\u001b[0m, in \u001b[0;36mParser._try_convert_to_date\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m   1354\u001b[0m         warnings\u001b[39m.\u001b[39mfilterwarnings(\n\u001b[1;32m   1355\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1356\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m.*parsing datetimes with mixed time \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1357\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mzones will raise an error\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1358\u001b[0m             category\u001b[39m=\u001b[39m\u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1359\u001b[0m         )\n\u001b[0;32m-> 1360\u001b[0m         new_data \u001b[39m=\u001b[39m to_datetime(new_data, errors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mraise\u001b[39;49m\u001b[39m\"\u001b[39;49m, unit\u001b[39m=\u001b[39;49mdate_unit)\n\u001b[1;32m   1361\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mOverflowError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m   1362\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[39m=\u001b[39m convert_listlike(arg\u001b[39m.\u001b[39;49m_values, \u001b[39mformat\u001b[39;49m)\n\u001b[1;32m   1068\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39m_constructor(values, index\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[39m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:407\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot specify both format and unit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m     \u001b[39mreturn\u001b[39;00m _to_datetime_with_unit(arg, unit, name, utc, errors)\n\u001b[1;32m    408\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mgetattr\u001b[39m(arg, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marg must be a string, datetime, list, tuple, 1-d array, or Series\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:512\u001b[0m, in \u001b[0;36m_to_datetime_with_unit\u001b[0;34m(arg, unit, name, utc, errors)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(over\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    511\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m         arr \u001b[39m=\u001b[39m cast_from_unit_vectorized(arg, unit\u001b[39m=\u001b[39;49munit)\n\u001b[1;32m    513\u001b[0m     \u001b[39mexcept\u001b[39;00m OutOfBoundsDatetime:\n\u001b[1;32m    514\u001b[0m         \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32mconversion.pyx:149\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.cast_from_unit_vectorized\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:3451\u001b[0m, in \u001b[0;36mround\u001b[0;34m(a, decimals, out)\u001b[0m\n\u001b[1;32m   3360\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_round_dispatcher)\n\u001b[1;32m   3361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mround\u001b[39m(a, decimals\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3362\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3363\u001b[0m \u001b[39m    Evenly round to the given number of decimals.\u001b[39;00m\n\u001b[1;32m   3364\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3449\u001b[0m \n\u001b[1;32m   3450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3451\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mround\u001b[39;49m\u001b[39m'\u001b[39;49m, decimals\u001b[39m=\u001b[39;49mdecimals, out\u001b[39m=\u001b[39;49mout)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: overflow encountered in multiply"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"hf://datasets/JonathanSum/github-issues/datasets-issues-with-comments.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c33f58-75e6-450f-893a-c4994b165da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>author_association</th>\n",
       "      <th>active_lock_reason</th>\n",
       "      <th>body</th>\n",
       "      <th>reactions</th>\n",
       "      <th>timeline_url</th>\n",
       "      <th>performed_via_github_app</th>\n",
       "      <th>draft</th>\n",
       "      <th>pull_request</th>\n",
       "      <th>is_pull_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>1089730181</td>\n",
       "      <td>I_kwDODunzps5A8_aF</td>\n",
       "      <td>3490</td>\n",
       "      <td>Does datasets support load text from HDFS?</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The raw text data is stored on HDFS due to the...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/pull/3489</td>\n",
       "      <td>1089401926</td>\n",
       "      <td>PR_kwDODunzps4wT97d</td>\n",
       "      <td>3489</td>\n",
       "      <td>Avoid unnecessary list creations</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CONTRIBUTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Like in `join([... for s in ...])`. Also chang...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>1089345653</td>\n",
       "      <td>I_kwDODunzps5A7hh1</td>\n",
       "      <td>3488</td>\n",
       "      <td>URL query parameters are set as path in the co...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>MEMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>## Describe the bug\\r\\nThere is an ssue with `...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/pull/3487</td>\n",
       "      <td>1089209031</td>\n",
       "      <td>PR_kwDODunzps4wTVeN</td>\n",
       "      <td>3487</td>\n",
       "      <td>Update ADD_NEW_DATASET.md</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-12-27 15:00:45</td>\n",
       "      <td>CONTRIBUTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fixed make style prompt for Windows Terminal</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/pull/3486</td>\n",
       "      <td>1089171551</td>\n",
       "      <td>PR_kwDODunzps4wTNd1</td>\n",
       "      <td>3486</td>\n",
       "      <td>Fix weird spacing in ManualDownloadError message</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-12-28 09:00:28</td>\n",
       "      <td>CONTRIBUTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>`textwrap.dedent` works based on the spaces at...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...   \n",
       "1  https://api.github.com/repos/huggingface/datas...   \n",
       "2  https://api.github.com/repos/huggingface/datas...   \n",
       "3  https://api.github.com/repos/huggingface/datas...   \n",
       "4  https://api.github.com/repos/huggingface/datas...   \n",
       "\n",
       "                                      repository_url  \\\n",
       "0  https://api.github.com/repos/huggingface/datasets   \n",
       "1  https://api.github.com/repos/huggingface/datasets   \n",
       "2  https://api.github.com/repos/huggingface/datasets   \n",
       "3  https://api.github.com/repos/huggingface/datasets   \n",
       "4  https://api.github.com/repos/huggingface/datasets   \n",
       "\n",
       "                                          labels_url  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...   \n",
       "1  https://api.github.com/repos/huggingface/datas...   \n",
       "2  https://api.github.com/repos/huggingface/datas...   \n",
       "3  https://api.github.com/repos/huggingface/datas...   \n",
       "4  https://api.github.com/repos/huggingface/datas...   \n",
       "\n",
       "                                        comments_url  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...   \n",
       "1  https://api.github.com/repos/huggingface/datas...   \n",
       "2  https://api.github.com/repos/huggingface/datas...   \n",
       "3  https://api.github.com/repos/huggingface/datas...   \n",
       "4  https://api.github.com/repos/huggingface/datas...   \n",
       "\n",
       "                                          events_url  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...   \n",
       "1  https://api.github.com/repos/huggingface/datas...   \n",
       "2  https://api.github.com/repos/huggingface/datas...   \n",
       "3  https://api.github.com/repos/huggingface/datas...   \n",
       "4  https://api.github.com/repos/huggingface/datas...   \n",
       "\n",
       "                                            html_url          id  \\\n",
       "0  https://github.com/huggingface/datasets/issues...  1089730181   \n",
       "1  https://github.com/huggingface/datasets/pull/3489  1089401926   \n",
       "2  https://github.com/huggingface/datasets/issues...  1089345653   \n",
       "3  https://github.com/huggingface/datasets/pull/3487  1089209031   \n",
       "4  https://github.com/huggingface/datasets/pull/3486  1089171551   \n",
       "\n",
       "               node_id  number  \\\n",
       "0   I_kwDODunzps5A8_aF    3490   \n",
       "1  PR_kwDODunzps4wT97d    3489   \n",
       "2   I_kwDODunzps5A7hh1    3488   \n",
       "3  PR_kwDODunzps4wTVeN    3487   \n",
       "4  PR_kwDODunzps4wTNd1    3486   \n",
       "\n",
       "                                               title  ...           closed_at  \\\n",
       "0         Does datasets support load text from HDFS?  ...                 NaT   \n",
       "1                   Avoid unnecessary list creations  ...                 NaT   \n",
       "2  URL query parameters are set as path in the co...  ...                 NaT   \n",
       "3                          Update ADD_NEW_DATASET.md  ... 2021-12-27 15:00:45   \n",
       "4   Fix weird spacing in ManualDownloadError message  ... 2021-12-28 09:00:28   \n",
       "\n",
       "  author_association active_lock_reason  \\\n",
       "0               NONE                NaN   \n",
       "1        CONTRIBUTOR                NaN   \n",
       "2             MEMBER                NaN   \n",
       "3        CONTRIBUTOR                NaN   \n",
       "4        CONTRIBUTOR                NaN   \n",
       "\n",
       "                                                body  \\\n",
       "0  The raw text data is stored on HDFS due to the...   \n",
       "1  Like in `join([... for s in ...])`. Also chang...   \n",
       "2  ## Describe the bug\\r\\nThere is an ssue with `...   \n",
       "3       fixed make style prompt for Windows Terminal   \n",
       "4  `textwrap.dedent` works based on the spaces at...   \n",
       "\n",
       "                                           reactions  \\\n",
       "0  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "1  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "2  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "3  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "4  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "\n",
       "                                        timeline_url performed_via_github_app  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...                      NaN   \n",
       "1  https://api.github.com/repos/huggingface/datas...                      NaN   \n",
       "2  https://api.github.com/repos/huggingface/datas...                      NaN   \n",
       "3  https://api.github.com/repos/huggingface/datas...                      NaN   \n",
       "4  https://api.github.com/repos/huggingface/datas...                      NaN   \n",
       "\n",
       "  draft                                       pull_request is_pull_request  \n",
       "0   NaN                                               None           False  \n",
       "1   0.0  {'url': 'https://api.github.com/repos/huggingf...            True  \n",
       "2   NaN                                               None           False  \n",
       "3   0.0  {'url': 'https://api.github.com/repos/huggingf...            True  \n",
       "4   0.0  {'url': 'https://api.github.com/repos/huggingf...            True  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc8248-fbf5-4cd1-9c56-4fcaabb42706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bug', 'enhancement', 'dataset request', 'dataset-viewer',\n",
       "       'good first issue', 'dataset bug', 'documentation', 'streaming',\n",
       "       'question', 'generic discussion', 'refactoring',\n",
       "       'Dataset discussion', 'wontfix', 'nlp-viewer', 'metric bug',\n",
       "       'duplicate', 'Metric discussion', 'metric request', 'help wanted'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_converter(data):\n",
    "    label_mapping = {\n",
    "        # New Feature\n",
    "        'enhancement': 'new_feature',\n",
    "        'dataset request': 'new_feature',\n",
    "        'metric request': 'new_feature',\n",
    "        # Improvement\n",
    "        'documentation': 'Improvement',\n",
    "        'streaming': 'Improvement',\n",
    "        'refactoring': 'Improvement',\n",
    "        'nlp-viewer': 'Improvement',\n",
    "        # Bug\n",
    "        'bug': 'bug',\n",
    "        'dataset bug': 'bug',\n",
    "        'metric bug': 'bug',\n",
    "    }\n",
    "    data['class'] = data['label'].apply(lambda x: label_mapping.get(x, 'Task'))\n",
    "    return data[['title', 'body', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660895ae-50a3-4ef9-8646-309b6602daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parser(data):\n",
    "    data_filtered = data[data['labels'].apply(lambda x: len(x) > 0)]\n",
    "    data_filtered['label'] = data_filtered['labels'].apply(lambda x: x[0]['name'].lower() if len(x) > 0 else None)\n",
    "    parsed_data = data_filtered[['label', 'title', 'body']]\n",
    "    final_data = feature_converter(parsed_data)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data_parser(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
